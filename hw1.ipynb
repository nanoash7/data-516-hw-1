{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3281a285",
   "metadata": {},
   "source": [
    "# Data 516 Homework 1\n",
    "Author: Ashwin Naresh\n",
    "\n",
    "In this assignment, we will be cleaning and validating server quote data and using it to create some tables. \n",
    "\n",
    "We need to perform the following validations on our quote data:\n",
    "\n",
    "Quotes for a given month can only be accepted starting on the first Monday of the month and ending on the 25th. These boundary dates are inclusive. Any quotes provided outside of these dates will not be considered. The sum of the quote line details must match the provided quote summary total. If the two datasets do not agree, the quotes will not be considered. We do not purchase Program C and Program E quotes from Vendor 7. Vendor 7â€™s systems are configured to quote all available programs, so these quotes need to be discarded.\n",
    "\n",
    "We will create the following tables:\n",
    "- The table of extended quantites per component for all programs.\n",
    "- The table of total cost per program per vendor, based on the latest received quote.\n",
    "- The table of total cost per program per vendor, based on the first received quote.\n",
    "- The table of \"best-in-class\" total cost per program (regardless of vendor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eea9ec43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from datetime import datetime\n",
    "    import polars as pl\n",
    "    import pandas as pd\n",
    "    import openpyxl\n",
    "except ImportError:\n",
    "    !pip install polars\n",
    "    import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ad904",
   "metadata": {},
   "source": [
    "## Data Cleaning and Validation\n",
    "In this step, we will read in the various data files and clean/validate the data according to our specifications. We will be joining these data sets together in order to create the tables in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd46e772",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_quotelines_raw = pl.read_csv(\"quote_lines.csv\")\n",
    "\n",
    "# Remove entries that are not between the first monday and the 25th (Sept 2nd through Sept 25th)\n",
    "df_quotelines_timefilter = (\n",
    "    df_quotelines_raw\n",
    "    .with_columns(pl.col(\"quote_timestamp\").str.to_datetime())\n",
    "    .filter(pl.col(\"quote_timestamp\").is_between(datetime(2024, 9, 2), datetime(2024, 9, 26)))\n",
    ")\n",
    "\n",
    "# Remove program C and program E quotes from Vendor 7\n",
    "df_quotelines_noCE = (\n",
    "    df_quotelines_timefilter\n",
    "    .filter((pl.col(\"Vendor\") != \"Vendor_7\") | ((pl.col(\"Program\") != \"Program_C\") & (pl.col(\"Program\") != \"Program_E\")))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dab0d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reads in the server config and rack config files, transposes them, and clears up the table\n",
    "def read_config_and_adjust(df):\n",
    "    df_transposed = df.transpose(include_header=True)\n",
    "    df_transposed = df_transposed.rename({\"column\": \"Program\"})\n",
    "    columns = [\"Program\"] + df[\"Item\"].to_list()\n",
    "    df_transposed.columns = columns\n",
    "    df_dropped = df_transposed.slice(1)\n",
    "    return df_dropped\n",
    "\n",
    "# Read in the configuration files\n",
    "df_server_raw = pl.read_csv(\"server_configurations.csv\")\n",
    "df_rack_raw = pl.read_csv(\"rack_configurations.csv\")\n",
    "\n",
    "df_server_specs = read_config_and_adjust(df_server_raw)\n",
    "df_rack_specs = read_config_and_adjust(df_rack_raw)\n",
    "\n",
    "# Join the server and rack config tables\n",
    "df_joined = df_server_specs.join(df_rack_specs, on=\"Program\", how=\"inner\")\n",
    "\n",
    "# Cast the numerical fields to floats and rename the columns\n",
    "df_config = df_joined.with_columns([\n",
    "    pl.col(\"CPU\").cast(pl.Float64).alias(\"CPU_COUNT\"),\n",
    "    pl.col(\"GPU\").cast(pl.Float64).alias(\"GPU_COUNT\"),\n",
    "    pl.col(\"RAM\").cast(pl.Float64).alias(\"RAM_COUNT\"),\n",
    "    pl.col(\"SSD\").cast(pl.Float64).alias(\"SSD_COUNT\"),\n",
    "    pl.col(\"HDD\").cast(pl.Float64).alias(\"HDD_COUNT\"),\n",
    "    pl.col(\"MOBO\").cast(pl.Float64).alias(\"MOBO_COUNT\"),\n",
    "    pl.col(\"NIC\").cast(pl.Float64).alias(\"NIC_COUNT\"),\n",
    "    pl.col(\"PSU\").cast(pl.Float64).alias(\"PSU_COUNT\"),\n",
    "    pl.col(\"TRAY\").cast(pl.Float64).alias(\"TRAY_COUNT\"),\n",
    "    pl.col(\"SERVERS\").cast(pl.Float64).alias(\"SERVER_COUNT\"),\n",
    "    pl.col(\"TOR\").cast(pl.Float64).alias(\"TOR_COUNT\"),\n",
    "    pl.col(\"CHASSIS\").cast(pl.Float64).alias(\"CHASSIS_COUNT\")\n",
    "]).drop(\"CPU\",\"GPU\",\"RAM\",\"SSD\",\"HDD\",\"MOBO\",\"NIC\",\"PSU\",\"TRAY\",\"SERVERS\",\"TOR\",\"CHASSIS\")\n",
    "\n",
    "# Rename the entries in the Program column to make the next merge easier\n",
    "df_config_final = df_config.with_columns(\n",
    "    pl.Series([\"Program_A\", \"Program_B\", \"Program_C\", \"Program_D\", \"Program_E\"]).alias(\"Program\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bea4d1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Join the quote data with the config data\n",
    "df_quote_config = df_quotelines_noCE.join(df_config_final, on=\"Program\", how=\"inner\")\n",
    "\n",
    "# Calculate the totals\n",
    "df_quote_config_totals = df_quote_config.with_columns(\n",
    "    ((pl.col(\"SERVER_COUNT\") * \n",
    "    ((pl.col(\"CPU\") * pl.col(\"CPU_COUNT\")) + \n",
    "    (pl.col(\"GPU\") * pl.col(\"GPU_COUNT\")) +\n",
    "    (pl.col(\"RAM\") * pl.col(\"RAM_COUNT\")) +\n",
    "    (pl.col(\"SSD\") * pl.col(\"SSD_COUNT\")) +\n",
    "    (pl.col(\"HDD\") * pl.col(\"HDD_COUNT\")) +\n",
    "    (pl.col(\"MOBO\") * pl.col(\"MOBO_COUNT\")) +\n",
    "    (pl.col(\"NIC\") * pl.col(\"NIC_COUNT\")) +\n",
    "    (pl.col(\"PSU\") * pl.col(\"PSU_COUNT\")) +\n",
    "    (pl.col(\"TRAY\") * pl.col(\"TRAY_COUNT\")))) + \n",
    "    (pl.col(\"TOR\") * pl.col(\"TOR_COUNT\")) + \n",
    "    (pl.col(\"CHASSIS\") * pl.col(\"CHASSIS_COUNT\"))).alias(\"TOTAL\")\n",
    ")\n",
    "\n",
    "# Read in the quote summary data get it ready for joining\n",
    "df_quotesummary_raw = pl.read_csv(\"quote_summaries.csv\")\n",
    "df_quotesummary_dt = (\n",
    "    df_quotesummary_raw\n",
    "    .with_columns(pl.col(\"quote_timestamp\").str.to_datetime())\n",
    "    .with_columns(pl.concat_str([pl.lit(\"Program_\"), pl.col(\"program\")]).alias(\"program\"))\n",
    ")\n",
    "\n",
    "# Join the quote config data with the summary data and drop the rows where the totals do not match\n",
    "df_cleaned = (\n",
    "    df_quote_config_totals\n",
    "    .join(\n",
    "        df_quotesummary_dt,\n",
    "        left_on=[\"Vendor\", \"Program\", \"quote_timestamp\"],\n",
    "        right_on=[\"vendor\", \"program\", \"quote_timestamp\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    .with_columns(pl.col(\"TOTAL\").round(2))\n",
    "    .filter(pl.col(\"TOTAL\") == pl.col(\"reported_total_price\"))\n",
    "    .drop(pl.col(\"reported_total_price\"))\n",
    ")\n",
    "\n",
    "df_cleaned.write_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c38279",
   "metadata": {},
   "source": [
    "## Table Creation\n",
    "In this step, we will be creating our output tables. Each of the following code cell contains the code for creating one of the four tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95a44a50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Component  Program_A  Program_B  Program_C  Program_D  Program_E\n",
      "0       CPU_COUNT      648.0      336.0      868.0      320.0      320.0\n",
      "1       GPU_COUNT        0.0      672.0        0.0        0.0      640.0\n",
      "2       RAM_COUNT     1296.0      672.0     1736.0     2560.0     2560.0\n",
      "3       SSD_COUNT      324.0      336.0      434.0      320.0        0.0\n",
      "4       HDD_COUNT        0.0        0.0        0.0     6400.0     6400.0\n",
      "5      MOBO_COUNT      324.0      168.0      434.0      320.0      320.0\n",
      "6       NIC_COUNT      648.0      336.0      868.0      640.0      320.0\n",
      "7       PSU_COUNT      324.0      336.0      434.0      320.0      320.0\n",
      "8      TRAY_COUNT      324.0      168.0      434.0      320.0      320.0\n",
      "9       TOR_COUNT       27.0       42.0       31.0       32.0       32.0\n",
      "10  CHASSIS_COUNT       27.0       21.0       31.0       32.0       32.0\n"
     ]
    }
   ],
   "source": [
    "# Table 1: The table of extended quantites per component for all programs.\n",
    "# Each row represents a distinct component and each attribute in the row corresponds to a unique program.\n",
    "\n",
    "# Drop the other columns\n",
    "df_t1_1 = df_cleaned.drop(\"CPU\", \"GPU\", \"RAM\", \"SSD\", \"HDD\", \"MOBO\", \"NIC\", \"PSU\", \"TRAY\", \"TOR\", \"CHASSIS\", \"quote_timestamp\", \"Vendor\", \"TOTAL\")\n",
    "\n",
    "# Caluclate the total counts\n",
    "columns = [\"CPU_COUNT\", \"GPU_COUNT\", \"RAM_COUNT\", \"SSD_COUNT\", \"HDD_COUNT\", \"MOBO_COUNT\", \"NIC_COUNT\", \"PSU_COUNT\", \"TRAY_COUNT\"]\n",
    "df_t1_2 = (df_t1_1\n",
    "    .with_columns((pl.col(col) * pl.col(\"SERVER_COUNT\")).alias(col) for col in columns)\n",
    "    .drop(\"SERVER_COUNT\")\n",
    ")\n",
    "\n",
    "# Aggreagate the counts by Program\n",
    "df_t1_3 = df_t1_2.group_by(\"Program\").agg([\n",
    "    pl.sum(col).alias(col) for col in df_t1_2.columns[1:]\n",
    "])\n",
    "\n",
    "# Unpivot then pivot to transpose the table\n",
    "df_t1_4 = df_t1_3.unpivot(index=\"Program\", variable_name=\"Component\")\n",
    "df_t1_4 = df_t1_4.pivot(on=\"Program\", index=\"Component\", values=\"value\", aggregate_function=\"sum\", sort_columns=True)\n",
    "\n",
    "# Convert to pandas dataframe for better display\n",
    "df_pandas = df_t1_4.to_pandas()\n",
    "print(df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad0703b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Program    Vendor     TOTAL\n",
      "0   Program_A  Vendor_1  18226.44\n",
      "1   Program_A  Vendor_2  17658.75\n",
      "2   Program_A  Vendor_3  18337.45\n",
      "3   Program_A  Vendor_4  18097.66\n",
      "4   Program_A  Vendor_5  17566.51\n",
      "5   Program_A  Vendor_6  17916.74\n",
      "6   Program_A  Vendor_7  18200.79\n",
      "7   Program_B  Vendor_1  31664.18\n",
      "8   Program_B  Vendor_2  31166.21\n",
      "9   Program_B  Vendor_3  32049.37\n",
      "10  Program_B  Vendor_4  29267.06\n",
      "11  Program_B  Vendor_5  29148.99\n",
      "12  Program_B  Vendor_6  28146.80\n",
      "13  Program_B  Vendor_7  31640.69\n",
      "14  Program_C  Vendor_1  20237.50\n",
      "15  Program_C  Vendor_2  20375.36\n",
      "16  Program_C  Vendor_3  20095.09\n",
      "17  Program_C  Vendor_4  20938.11\n",
      "18  Program_C  Vendor_5  21211.93\n",
      "19  Program_C  Vendor_6  21211.09\n",
      "20  Program_D  Vendor_1  38139.87\n",
      "21  Program_D  Vendor_2  50639.78\n",
      "22  Program_D  Vendor_3  48570.62\n",
      "23  Program_D  Vendor_4  41156.46\n",
      "24  Program_D  Vendor_5  52326.86\n",
      "25  Program_D  Vendor_6  47118.18\n",
      "26  Program_D  Vendor_7  34309.11\n",
      "27  Program_E  Vendor_1  56903.34\n",
      "28  Program_E  Vendor_2  60823.12\n",
      "29  Program_E  Vendor_3  50823.06\n",
      "30  Program_E  Vendor_4  55786.45\n",
      "31  Program_E  Vendor_5  43245.08\n",
      "32  Program_E  Vendor_6  49034.84\n"
     ]
    }
   ],
   "source": [
    "# Table 2: The table of total cost per program per vendor, based on the latest received quote.\n",
    "\n",
    "df_t2_1 = df_cleaned.select([\"Program\", \"Vendor\", \"quote_timestamp\", \"TOTAL\"])\n",
    "sorted_df = df_t2_1.sort(\"quote_timestamp\", descending=True)\n",
    "\n",
    "df_t2_2 = sorted_df.group_by([\"Program\", \"Vendor\"]).agg(pl.all().first())\n",
    "df_t2_3 = df_t2_2.sort([\"Program\", \"Vendor\"]).drop(\"quote_timestamp\")\n",
    "\n",
    "# Convert to pandas dataframe for better display\n",
    "df_pandas = df_t2_3.to_pandas()\n",
    "print(df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6673a742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Program    Vendor     TOTAL\n",
      "0   Program_A  Vendor_1  17555.80\n",
      "1   Program_A  Vendor_2  18287.76\n",
      "2   Program_A  Vendor_3  18934.65\n",
      "3   Program_A  Vendor_4  18547.48\n",
      "4   Program_A  Vendor_5  17768.43\n",
      "5   Program_A  Vendor_6  17866.88\n",
      "6   Program_A  Vendor_7  18099.99\n",
      "7   Program_B  Vendor_1  30304.36\n",
      "8   Program_B  Vendor_2  30943.99\n",
      "9   Program_B  Vendor_3  30001.48\n",
      "10  Program_B  Vendor_4  29267.06\n",
      "11  Program_B  Vendor_5  30455.55\n",
      "12  Program_B  Vendor_6  32021.13\n",
      "13  Program_B  Vendor_7  31640.69\n",
      "14  Program_C  Vendor_1  21839.65\n",
      "15  Program_C  Vendor_2  21206.47\n",
      "16  Program_C  Vendor_3  21841.24\n",
      "17  Program_C  Vendor_4  20741.65\n",
      "18  Program_C  Vendor_5  20617.44\n",
      "19  Program_C  Vendor_6  20719.93\n",
      "20  Program_D  Vendor_1  35885.62\n",
      "21  Program_D  Vendor_2  45809.01\n",
      "22  Program_D  Vendor_3  39012.08\n",
      "23  Program_D  Vendor_4  39211.48\n",
      "24  Program_D  Vendor_5  54559.00\n",
      "25  Program_D  Vendor_6  44603.39\n",
      "26  Program_D  Vendor_7  39209.79\n",
      "27  Program_E  Vendor_1  58606.86\n",
      "28  Program_E  Vendor_2  48245.24\n",
      "29  Program_E  Vendor_3  47761.56\n",
      "30  Program_E  Vendor_4  61305.92\n",
      "31  Program_E  Vendor_5  44481.12\n",
      "32  Program_E  Vendor_6  57354.15\n"
     ]
    }
   ],
   "source": [
    "# Table 3: The table of total cost per program per vendor, based on the first received quote.\n",
    "\n",
    "df_t3_1 = df_cleaned.select([\"Program\", \"Vendor\", \"quote_timestamp\", \"TOTAL\"])\n",
    "sorted_df = df_t3_1.sort(\"quote_timestamp\", descending=False)\n",
    "\n",
    "df_t3_2 = sorted_df.group_by([\"Program\", \"Vendor\"]).agg(pl.all().first())\n",
    "df_t3_3 = df_t3_2.sort([\"Program\", \"Vendor\"]).drop(\"quote_timestamp\")\n",
    "\n",
    "# Convert to pandas dataframe for better display\n",
    "df_pandas = df_t3_3.to_pandas()\n",
    "print(df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6c369a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Program     CPU     GPU    RAM     SSD     HDD   MOBO    NIC    PSU  \\\n",
      "0  Program_A  300.29  400.41  44.22  180.83  105.42  81.27  20.28  81.49   \n",
      "1  Program_B  300.53  403.88  44.42  180.59  102.50  81.36  20.64  82.23   \n",
      "2  Program_C  302.02  400.56  44.18  180.34  103.75  81.36  20.59  82.47   \n",
      "3  Program_D  301.36  408.34  44.60  180.24  100.89  80.72  20.98  81.97   \n",
      "4  Program_E  301.77  410.57  44.11  180.53  101.95  81.18  20.19  80.39   \n",
      "\n",
      "    TRAY     TOR  CHASSIS     TOTAL  \n",
      "0  19.99  507.45  1097.67  15784.32  \n",
      "1  12.33  503.87  1018.23  26464.93  \n",
      "2  14.48  502.95  1007.48  18038.69  \n",
      "3  11.57  508.13  1015.84  32248.17  \n",
      "4  11.57  523.49  1009.27  38613.96  \n"
     ]
    }
   ],
   "source": [
    "# Table 4: The table of \"best-in-class\" total cost per program (regardless of vendor).\n",
    "\n",
    "df_t4_1 = df_cleaned.drop(\"quote_timestamp\", \"Vendor\", \"TOTAL\")\n",
    "\n",
    "df_t4_2 = df_t4_1.group_by(\"Program\").agg([\n",
    "    pl.min(col) for col in df_t4_1.columns[1:]\n",
    "]).sort(\"Program\")\n",
    "\n",
    "df_t4_3 = df_t4_2.with_columns(\n",
    "    ((pl.col(\"SERVER_COUNT\") * \n",
    "    ((pl.col(\"CPU\") * pl.col(\"CPU_COUNT\")) + \n",
    "    (pl.col(\"GPU\") * pl.col(\"GPU_COUNT\")) +\n",
    "    (pl.col(\"RAM\") * pl.col(\"RAM_COUNT\")) +\n",
    "    (pl.col(\"SSD\") * pl.col(\"SSD_COUNT\")) +\n",
    "    (pl.col(\"HDD\") * pl.col(\"HDD_COUNT\")) +\n",
    "    (pl.col(\"MOBO\") * pl.col(\"MOBO_COUNT\")) +\n",
    "    (pl.col(\"NIC\") * pl.col(\"NIC_COUNT\")) +\n",
    "    (pl.col(\"PSU\") * pl.col(\"PSU_COUNT\")) +\n",
    "    (pl.col(\"TRAY\") * pl.col(\"TRAY_COUNT\")))) + \n",
    "    (pl.col(\"TOR\") * pl.col(\"TOR_COUNT\")) + \n",
    "    (pl.col(\"CHASSIS\") * pl.col(\"CHASSIS_COUNT\"))).alias(\"TOTAL\")\n",
    ")\n",
    "\n",
    "df_t4_4 = df_t4_3.select([\"Program\", \"CPU\", \"GPU\", \"RAM\", \"SSD\", \"HDD\", \"MOBO\", \"NIC\", \"PSU\", \"TRAY\", \"TOR\", \"CHASSIS\", \"TOTAL\"])\n",
    "\n",
    "# Convert to pandas dataframe for better display\n",
    "df_pandas = df_t4_4.to_pandas()\n",
    "print(df_pandas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
